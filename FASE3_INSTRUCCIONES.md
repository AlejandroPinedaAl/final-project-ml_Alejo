# üìã FASE 3: ENTRENAMIENTO Y EVALUACI√ìN DE MODELOS - INSTRUCCIONES

## ‚úÖ LIBRER√çAS NECESARIAS

### Librer√≠as ya instaladas (de la Fase 2):
- ‚úÖ pandas
- ‚úÖ numpy
- ‚úÖ matplotlib
- ‚úÖ seaborn
- ‚úÖ scipy
- ‚úÖ scikit-learn
- ‚úÖ joblib

### Librer√≠as instaladas para la Fase 3:

```bash
pip install xgboost lightgbm
```

**Verificar instalaci√≥n**:
```bash
pip list | findstr "xgboost lightgbm scikit-learn"
```

Debes ver:
- xgboost (versi√≥n 3.x o superior)
- lightgbm (versi√≥n 4.x o superior)
- scikit-learn (versi√≥n 1.7.x o superior)

---

## üì¶ DEPENDENCIAS COMPLETAS

### Comandos de instalaci√≥n:

```bash
# Instalar XGBoost
pip install xgboost

# Instalar LightGBM
pip install lightgbm
```

### Verificar instalaci√≥n:

```bash
python -c "import xgboost; print('XGBoost:', xgboost.__version__)"
python -c "import lightgbm; print('LightGBM:', lightgbm.__version__)"
python -c "import sklearn; print('scikit-learn:', sklearn.__version__)"
```

---

## üìì NOTEBOOK CREADO

**Archivo**: `mlops_pipeline/src/model_training_evaluation_fase3.ipynb`

Este notebook contiene todas las celdas necesarias para ejecutar la Fase 3 completa.

---

## üöÄ PASOS PARA EJECUTAR LA FASE 3

### 1. Verificar que la Fase 2 est√© completada

Aseg√∫rate de que tengas los siguientes archivos en la ra√≠z del proyecto:
- ‚úÖ `X_train_transformed.csv`
- ‚úÖ `X_test_transformed.csv`
- ‚úÖ `y_train.csv`
- ‚úÖ `y_test.csv`
- ‚úÖ `preprocessor.pkl` (opcional pero recomendado)

### 2. Abrir el notebook

```bash
# Desde Jupyter Notebook o JupyterLab
jupyter notebook mlops_pipeline/src/model_training_evaluation_fase3.ipynb
```

O desde VS Code:
- Abre el archivo `model_training_evaluation_fase3.ipynb`
- Selecciona el kernel de Python

### 3. Ejecutar las celdas en orden

El notebook est√° organizado en las siguientes secciones:

1. **Importaci√≥n de Librer√≠as** (Celda 1)
2. **Carga de Datos** (Celdas 2-5)
   - Cargar datos transformados
   - Verificar distribuci√≥n de clases
   - Cargar preprocessor
3. **Definici√≥n de Modelos** (Celdas 6-8)
   - Calcular peso para balanceo
   - Definir 7 modelos
4. **Funci√≥n de Entrenamiento** (Celda 9)
   - Funci√≥n `build_model()` completa
5. **Entrenamiento de Modelos** (Celdas 10-11)
   - Entrenar los 7 modelos
   - Validaci√≥n cruzada (5-fold)
6. **Comparaci√≥n de Modelos** (Celdas 12-14)
   - Tabla comparativa
   - Identificar mejor modelo
7. **Visualizaciones** (Celdas 15-19)
   - Comparaci√≥n de m√©tricas
   - Comparaci√≥n de ROC-AUC
   - Curvas ROC
   - Matrices de confusi√≥n
   - Feature importance
8. **Guardar Mejor Modelo** (Celdas 20-21)
   - Guardar modelo con metadata
9. **Resumen Final** (Celda 22)
10. **Verificaci√≥n** (Celda 23)

### 4. Verificar resultados

Despu√©s de ejecutar todas las celdas, deber√≠as tener los siguientes archivos:

- ‚úÖ `best_model.pkl` - Modelo entrenado con metadata
- ‚úÖ `model_comparison_metrics.png` - Gr√°fico de m√©tricas
- ‚úÖ `model_comparison_roc_auc.png` - Gr√°fico de ROC-AUC
- ‚úÖ `roc_curves_comparison.png` - Curvas ROC de todos los modelos
- ‚úÖ `confusion_matrices.png` - Matrices de confusi√≥n
- ‚úÖ `feature_importance_[modelo].png` - Importancia de features (si aplica)

---

## üîç VERIFICACI√ìN DE RESULTADOS

### Verificar que los archivos se crearon:

```bash
# Desde la ra√≠z del proyecto
dir best_model.pkl
dir model_comparison_*.png
dir roc_curves_comparison.png
dir confusion_matrices.png
```

### Verificar m√©tricas del mejor modelo:

El notebook imprime un resumen al final con:
- Nombre del mejor modelo
- F1-Score, ROC-AUC, Accuracy
- Tabla comparativa completa
- Gr√°ficos de visualizaci√≥n

---

## ‚ö†Ô∏è POSIBLES PROBLEMAS Y SOLUCIONES

### Problema 1: Error al cargar datos

**Error**: `FileNotFoundError: X_train_transformed.csv`

**Soluci√≥n**: Aseg√∫rate de haber ejecutado la Fase 2 primero y que los archivos est√©n en la ra√≠z del proyecto.

### Problema 2: Error con XGBoost o LightGBM

**Error**: `ModuleNotFoundError: No module named 'xgboost'`

**Soluci√≥n**: Instala las librer√≠as:
```bash
pip install xgboost lightgbm
```

### Problema 3: Error con class_weight='balanced'

**Error**: Algunos modelos pueden no soportar `class_weight='balanced'`

**Soluci√≥n**: El notebook maneja esto autom√°ticamente. Si hay errores, puedes comentar esos modelos temporalmente.

### Problema 4: Tiempo de entrenamiento muy largo

**Soluci√≥n**: 
- Reduce `n_estimators` en los modelos de ensemble (de 100 a 50)
- Reduce `cv_folds` de 5 a 3
- Comenta modelos que tarden mucho (SVM puede ser lento)

### Problema 5: Memory Error

**Soluci√≥n**:
- Reduce el tama√±o del dataset si es muy grande
- Usa `n_jobs=1` en lugar de `n_jobs=-1`
- Cierra otras aplicaciones

---

## üìä MODELOS QUE SE ENTRENAN

El notebook entrena los siguientes 7 modelos:

1. **Logistic Regression** (baseline)
   - R√°pido, interpretable
   - Class weight: balanced

2. **Random Forest** (ensemble)
   - Robusto, maneja bien desbalance
   - Class weight: balanced
   - n_estimators: 100

3. **Gradient Boosting** (boosting)
   - Buen rendimiento
   - n_estimators: 100

4. **Extra Trees** (ensemble)
   - Similar a Random Forest
   - Class weight: balanced
   - n_estimators: 100

5. **SVM** (kernel-based)
   - Puede ser lento con datasets grandes
   - Class weight: balanced
   - Kernel: RBF

6. **XGBoost** (boosting avanzado)
   - Excelente rendimiento
   - scale_pos_weight: calculado autom√°ticamente
   - n_estimators: 100

7. **LightGBM** (boosting r√°pido)
   - R√°pido y eficiente
   - Class weight: balanced
   - n_estimators: 100

---

## üìà M√âTRICAS QUE SE EVAL√öAN

Para cada modelo se calculan:

### M√©tricas B√°sicas:
- **Accuracy**: Precisi√≥n general
- **Precision**: Precisi√≥n de predicciones positivas
- **Recall**: Sensibilidad (captura de positivos)
- **F1-Score**: Media arm√≥nica de precision y recall

### M√©tricas Avanzadas:
- **ROC-AUC**: √Årea bajo la curva ROC
- **Average Precision**: Precisi√≥n promedio

### Validaci√≥n Cruzada:
- **5-fold estratificada**: Media y desviaci√≥n est√°ndar
- **M√©tricas**: accuracy, precision, recall, f1, roc_auc

### Overfitting Check:
- **Diferencia Train vs Test**: Accuracy y F1-Score
- **Umbral de alerta**: >0.1 diferencia

---

## üéØ SELECCI√ìN DEL MEJOR MODELO

El mejor modelo se selecciona basado en:

1. **F1-Score en Test**: M√©trica principal (balance entre precision y recall)
2. **ROC-AUC**: Capacidad de discriminaci√≥n
3. **Consistencia**: Bajo overfitting (train vs test)
4. **Validaci√≥n Cruzada**: Estabilidad en diferentes folds

**Criterios de selecci√≥n**:
- Mayor F1-Score
- ROC-AUC > 0.7 (bueno)
- Overfitting < 0.1 (bajo)
- CV std < 0.05 (consistente)

---

## üìä VISUALIZACIONES GENERADAS

### 1. Comparaci√≥n de M√©tricas Principales
- Gr√°fico de barras con Accuracy, Precision, Recall, F1-Score
- Comparaci√≥n visual de todos los modelos

### 2. Comparaci√≥n de ROC-AUC
- Gr√°fico de barras horizontales
- Ordenado por ROC-AUC

### 3. Curvas ROC
- Curvas ROC de todos los modelos en un solo gr√°fico
- L√≠nea de referencia (random classifier)
- AUC de cada modelo en la leyenda

### 4. Matrices de Confusi√≥n
- Grid de matrices de confusi√≥n (3 columnas)
- Una matriz por modelo
- Heatmaps con valores anotados

### 5. Feature Importance
- Top 20 features m√°s importantes
- Solo para modelos que lo soporten (tree-based)
- Gr√°fico de barras horizontales

---

## üíæ ARCHIVOS GENERADOS

### Archivos Principales:
1. **best_model.pkl**: Modelo entrenado con metadata completa
   - Modelo entrenado
   - M√©tricas de evaluaci√≥n
   - Preprocessor (opcional)
   - Nombres de features
   - Timestamp y versi√≥n

### Archivos de Visualizaci√≥n:
2. **model_comparison_metrics.png**: Comparaci√≥n de m√©tricas
3. **model_comparison_roc_auc.png**: Comparaci√≥n de ROC-AUC
4. **roc_curves_comparison.png**: Curvas ROC
5. **confusion_matrices.png**: Matrices de confusi√≥n
6. **feature_importance_[modelo].png**: Importancia de features

---

## ‚úÖ CHECKLIST DE VERIFICACI√ìN

Antes de pasar a la Fase 4, verifica que:

- [ ] Todas las celdas del notebook se ejecutaron sin errores
- [ ] El archivo `best_model.pkl` se cre√≥ correctamente
- [ ] Los gr√°ficos se guardaron correctamente
- [ ] La tabla comparativa muestra todos los modelos
- [ ] El mejor modelo tiene m√©tricas razonables (F1 > 0.5, ROC-AUC > 0.7)
- [ ] No hay overfitting excesivo (diferencia < 0.1)
- [ ] El modelo se puede cargar correctamente

---

## üéØ PR√ìXIMOS PASOS

Una vez completada la Fase 3:

1. ‚úÖ Verifica que todos los archivos se guardaron correctamente
2. ‚úÖ Revisa la tabla comparativa de modelos
3. ‚úÖ Analiza las visualizaciones
4. ‚úÖ Verifica que el mejor modelo tenga buen rendimiento
5. ‚úÖ Av√≠same cuando est√©s listo para la Fase 4

**Fase 4**: Monitoreo y Detecci√≥n de Data Drift
- Necesitar√°s: streamlit, scipy (ya instalados)
- Archivos de entrada: best_model.pkl, datos hist√≥ricos

---

## üìù NOTAS IMPORTANTES

1. **Tiempo de Ejecuci√≥n**: El entrenamiento puede tardar varios minutos (depende de tu m√°quina)
   - Logistic Regression: ~1 segundo
   - Random Forest: ~5-10 segundos
   - Gradient Boosting: ~10-20 segundos
   - XGBoost: ~5-10 segundos
   - LightGBM: ~3-5 segundos
   - SVM: ~30-60 segundos (puede ser m√°s lento)

2. **Balanceo de Clases**: Todos los modelos usan t√©cnicas de balanceo:
   - `class_weight='balanced'` en scikit-learn
   - `scale_pos_weight` en XGBoost
   - Esto es crucial para datasets desbalanceados

3. **Validaci√≥n Cruzada**: Se usa 5-fold estratificada para:
   - Evaluar estabilidad del modelo
   - Detectar overfitting
   - Obtener m√©tricas m√°s confiables

4. **Reproducibilidad**: Se usa `random_state=42` en todos los modelos para resultados reproducibles

5. **Guardado del Modelo**: El modelo se guarda con metadata completa para facilitar el despliegue en la Fase 5

---

## üîß CONFIGURACI√ìN AVANZADA

### Si quieres ajustar par√°metros:

Puedes modificar los modelos en la celda de definici√≥n:

```python
# Ejemplo: Aumentar n_estimators para mejor rendimiento (m√°s lento)
'Random Forest': RandomForestClassifier(
    n_estimators=200,  # Aumentado de 100 a 200
    random_state=42,
    class_weight='balanced',
    n_jobs=-1
)

# Ejemplo: Reducir cv_folds para ejecuci√≥n m√°s r√°pida
cv_folds = 3  # Reducido de 5 a 3
```

### Si quieres agregar m√°s modelos:

```python
# Agregar al diccionario de modelos
from sklearn.neural_network import MLPClassifier

models['Neural Network'] = MLPClassifier(
    hidden_layer_sizes=(100, 50),
    max_iter=500,
    random_state=42
)
```

---

## üìä INTERPRETACI√ìN DE RESULTADOS

### M√©tricas Clave:

- **F1-Score > 0.7**: Excelente
- **F1-Score > 0.6**: Bueno
- **F1-Score > 0.5**: Aceptable
- **F1-Score < 0.5**: Necesita mejora

- **ROC-AUC > 0.8**: Excelente
- **ROC-AUC > 0.7**: Bueno
- **ROC-AUC > 0.6**: Aceptable
- **ROC-AUC < 0.6**: Necesita mejora

### Overfitting:

- **Diferencia < 0.05**: Excelente (muy poco overfitting)
- **Diferencia < 0.1**: Bueno (poco overfitting)
- **Diferencia > 0.1**: Advertencia (posible overfitting)
- **Diferencia > 0.2**: Cr√≠tico (overfitting significativo)

---

**Fecha de creaci√≥n**: Noviembre 2025
**Autor**: Alejandro Pineda Alvarez
**Proyecto**: Marketing Campaign Response Prediction

